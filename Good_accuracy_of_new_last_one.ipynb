{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "-E7-W38XGLfq",
    "outputId": "f3708494-e994-4b63-e671-d05effe4c90f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Div,Date,HT,AT,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,BWH,BWD,BWA,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA,GB&gt;2.5,GB&lt;2.5,GBAHH,GBAHA,GBAH,,,,,,,,,,,</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,Referee,HS,AS,HST,AST,HF,AF,HC,AC,HY,AY,HR,AR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA,GB&gt;2.5,GB&lt;2.5</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,Referee,HS,AS,HST,AST,HF,AF,HC,AC,HY,AY,HR,AR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA,GB&gt;2.5,GB&lt;2.5,GBAHH,GBAHA,GBAH</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,BWH,BWD,BWA,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA,GBAHH,GBAHA,GBAH,,,,,,,,,,,,,,,</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA</th>\n",
       "      <th>Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA</th>\n",
       "      <th>Unnamed: 106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Malaga</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>La Coruna</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>Santander</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>Espanol</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Annan Athletic</td>\n",
       "      <td>Kelty Hearts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Cowdenbeath</td>\n",
       "      <td>Albion Rvs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Forfar</td>\n",
       "      <td>Stenhousemuir</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Stirling</td>\n",
       "      <td>Edinburgh City</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>Stranraer</td>\n",
       "      <td>Elgin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157784 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Div        Date        HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0    SP1    09/09/00       Barcelona          Malaga   2.0   1.0   H   2.0   \n",
       "1    SP1    09/09/00       La Coruna      Ath Bilbao   2.0   0.0   H   0.0   \n",
       "2    SP1    09/09/00     Real Madrid        Valencia   2.0   1.0   H   0.0   \n",
       "3    SP1    09/09/00        Sociedad       Santander   2.0   2.0   D   0.0   \n",
       "4    SP1    09/09/00        Zaragoza         Espanol   1.0   2.0   A   0.0   \n",
       "..   ...         ...             ...             ...   ...   ...  ..   ...   \n",
       "175  SC3  30/04/2022  Annan Athletic    Kelty Hearts   1.0   2.0   A   1.0   \n",
       "176  SC3  30/04/2022     Cowdenbeath      Albion Rvs   0.0   1.0   A   0.0   \n",
       "177  SC3  30/04/2022          Forfar   Stenhousemuir   0.0   0.0   D   0.0   \n",
       "178  SC3  30/04/2022        Stirling  Edinburgh City   5.0   0.0   H   4.0   \n",
       "179  SC3  30/04/2022       Stranraer           Elgin   2.0   0.0   H   0.0   \n",
       "\n",
       "     HTAG HTR  ...  Unnamed: 29  \\\n",
       "0     0.0   H  ...          NaN   \n",
       "1     0.0   D  ...          NaN   \n",
       "2     0.0   D  ...          NaN   \n",
       "3     0.0   D  ...          NaN   \n",
       "4     0.0   D  ...          NaN   \n",
       "..    ...  ..  ...          ...   \n",
       "175   2.0   A  ...          NaN   \n",
       "176   0.0   D  ...          NaN   \n",
       "177   0.0   D  ...          NaN   \n",
       "178   0.0   H  ...          NaN   \n",
       "179   0.0   D  ...          NaN   \n",
       "\n",
       "     Div,Date,HT,AT,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,BWH,BWD,BWA,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA,GB>2.5,GB<2.5,GBAHH,GBAHA,GBAH,,,,,,,,,,,  \\\n",
       "0                                                  NaN                                                                                                                                \n",
       "1                                                  NaN                                                                                                                                \n",
       "2                                                  NaN                                                                                                                                \n",
       "3                                                  NaN                                                                                                                                \n",
       "4                                                  NaN                                                                                                                                \n",
       "..                                                 ...                                                                                                                                \n",
       "175                                                NaN                                                                                                                                \n",
       "176                                                NaN                                                                                                                                \n",
       "177                                                NaN                                                                                                                                \n",
       "178                                                NaN                                                                                                                                \n",
       "179                                                NaN                                                                                                                                \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,Referee,HS,AS,HST,AST,HF,AF,HC,AC,HY,AY,HR,AR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA,GB>2.5,GB<2.5  \\\n",
       "0                                                  NaN                                                                                                                                                              \n",
       "1                                                  NaN                                                                                                                                                              \n",
       "2                                                  NaN                                                                                                                                                              \n",
       "3                                                  NaN                                                                                                                                                              \n",
       "4                                                  NaN                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                              \n",
       "175                                                NaN                                                                                                                                                              \n",
       "176                                                NaN                                                                                                                                                              \n",
       "177                                                NaN                                                                                                                                                              \n",
       "178                                                NaN                                                                                                                                                              \n",
       "179                                                NaN                                                                                                                                                              \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,Referee,HS,AS,HST,AST,HF,AF,HC,AC,HY,AY,HR,AR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA,GB>2.5,GB<2.5,GBAHH,GBAHA,GBAH  \\\n",
       "0                                                  NaN                                                                                                                                                                               \n",
       "1                                                  NaN                                                                                                                                                                               \n",
       "2                                                  NaN                                                                                                                                                                               \n",
       "3                                                  NaN                                                                                                                                                                               \n",
       "4                                                  NaN                                                                                                                                                                               \n",
       "..                                                 ...                                                                                                                                                                               \n",
       "175                                                NaN                                                                                                                                                                               \n",
       "176                                                NaN                                                                                                                                                                               \n",
       "177                                                NaN                                                                                                                                                                               \n",
       "178                                                NaN                                                                                                                                                                               \n",
       "179                                                NaN                                                                                                                                                                               \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA  \\\n",
       "0                                                  NaN                                                                                      \n",
       "1                                                  NaN                                                                                      \n",
       "2                                                  NaN                                                                                      \n",
       "3                                                  NaN                                                                                      \n",
       "4                                                  NaN                                                                                      \n",
       "..                                                 ...                                                                                      \n",
       "175                                                NaN                                                                                      \n",
       "176                                                NaN                                                                                      \n",
       "177                                                NaN                                                                                      \n",
       "178                                                NaN                                                                                      \n",
       "179                                                NaN                                                                                      \n",
       "\n",
       "     Unnamed: 53  \\\n",
       "0            NaN   \n",
       "1            NaN   \n",
       "2            NaN   \n",
       "3            NaN   \n",
       "4            NaN   \n",
       "..           ...   \n",
       "175          NaN   \n",
       "176          NaN   \n",
       "177          NaN   \n",
       "178          NaN   \n",
       "179          NaN   \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,BWH,BWD,BWA,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA,GBAHH,GBAHA,GBAH,,,,,,,,,,,,,,,  \\\n",
       "0                                                  NaN                                                                                                                                  \n",
       "1                                                  NaN                                                                                                                                  \n",
       "2                                                  NaN                                                                                                                                  \n",
       "3                                                  NaN                                                                                                                                  \n",
       "4                                                  NaN                                                                                                                                  \n",
       "..                                                 ...                                                                                                                                  \n",
       "175                                                NaN                                                                                                                                  \n",
       "176                                                NaN                                                                                                                                  \n",
       "177                                                NaN                                                                                                                                  \n",
       "178                                                NaN                                                                                                                                  \n",
       "179                                                NaN                                                                                                                                  \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,LBH,LBD,LBA,SBH,SBD,SBA,WHH,WHD,WHA  \\\n",
       "0                                                  NaN                                                                          \n",
       "1                                                  NaN                                                                          \n",
       "2                                                  NaN                                                                          \n",
       "3                                                  NaN                                                                          \n",
       "4                                                  NaN                                                                          \n",
       "..                                                 ...                                                                          \n",
       "175                                                NaN                                                                          \n",
       "176                                                NaN                                                                          \n",
       "177                                                NaN                                                                          \n",
       "178                                                NaN                                                                          \n",
       "179                                                NaN                                                                          \n",
       "\n",
       "     Div,Date,HomeTeam,AwayTeam,FTHG,FTAG,FTR,HTHG,HTAG,HTR,B365H,B365D,B365A,GBH,GBD,GBA,IWH,IWD,IWA,LBH,LBD,LBA,SOH,SOD,SOA,SBH,SBD,SBA,WHH,WHD,WHA  \\\n",
       "0                                                  NaN                                                                                                  \n",
       "1                                                  NaN                                                                                                  \n",
       "2                                                  NaN                                                                                                  \n",
       "3                                                  NaN                                                                                                  \n",
       "4                                                  NaN                                                                                                  \n",
       "..                                                 ...                                                                                                  \n",
       "175                                                NaN                                                                                                  \n",
       "176                                                NaN                                                                                                  \n",
       "177                                                NaN                                                                                                  \n",
       "178                                                NaN                                                                                                  \n",
       "179                                                NaN                                                                                                  \n",
       "\n",
       "     Unnamed: 106  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "..            ...  \n",
       "175           NaN  \n",
       "176           NaN  \n",
       "177           NaN  \n",
       "178           NaN  \n",
       "179           NaN  \n",
       "\n",
       "[157784 rows x 241 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATA_PATH = '/content/'\n",
    "# we create a dictionary dict_countries similar to the one we used in the scraping section\n",
    "# but in this case we need to specify the names considered in the link to download the csv e.g. \"SP1\" (Spanish League)\n",
    "dict_countries = {\n",
    "    \"Spanish La Liga\": \"SP1\", \"Spanish Segunda Division\": \"SP2\", \"German Bundesliga\": \"D1\", \"German Bundesliga 2\": \"D2\",\n",
    "    \"Italian Serie A\": \"I1\", \"English Premier League\": \"E0\", \"English Championship\": \"E1\", \"English League 1\": \"E2\",\n",
    "    \"English League 2\": \"E3\", \"English National\": \"EC\", \"French Ligue 1\": \"F1\", \"French Ligue 2\": \"F2\", \"Dutch Eredivisie\": \"N1\",\n",
    "    \"Belgian First Division A\": \"B1\", \"Portuguese Primeira Liga\": \"P1\", \"Turkish Super League\": \"T1\", \"Greek Super League\": \"G1\",\n",
    "    \"Scottish Premier League\": \"SC0\", \"Scottish League1\": \"SC1\", \"Scottish League2\": \"SC2\", \"Scottish League3\": \"SC3\"\n",
    "}\n",
    "\n",
    "# dict_historical_data contains data of the past 5 years. we'll use it to manage 2 dataframes: df_historical_data and df_profile\n",
    "dict_historical_data = {}\n",
    "\n",
    "# to download all the leagues we loop through the dictionary\n",
    "for league in dict_countries:\n",
    "    frames = []\n",
    "    for i in range(2000,2022):\n",
    "        s_year = int(str(i)[-2:])\n",
    "        try:\n",
    "            df = pd.read_csv(\"https://www.football-data.co.uk/mmz4281/\"+  str(s_year)+ str(s_year + 1)[-2:].zfill(2) +\"/\"+dict_countries[league]+\".csv\", encoding='windows-1252')\n",
    "        except:  # Italian Serie B (0xa0 utf-8)\n",
    "            try :\n",
    "                df = pd.read_csv(\"https://www.football-data.co.uk/mmz4281/\"+  str(s_year).zfill(2) + str(s_year + 1)[-2:].zfill(2) + \"/\"+ dict_countries[league]+\".csv\",encoding =\"unicode_escape\", sep='delimiter')#, header=None)\n",
    "            except:\n",
    "                continue\n",
    "        df = df.assign(season=s_year)\n",
    "        frames.append(df)\n",
    "    df_frames = pd.concat(frames)  \n",
    "    dict_historical_data[league] = df_frames\n",
    "\n",
    "leagues = list(dict_historical_data.keys())\n",
    "\n",
    "eu_leagues = dict_historical_data[leagues[0]]\n",
    "for l in leagues[1:]:\n",
    "    df = dict_historical_data[l]\n",
    "    eu_leagues = eu_leagues.append(df)\n",
    "#to_keep = ['Div','Date','Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC','AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A', 'B365>2.5', 'B365<2.5']\n",
    "all_leagues = eu_leagues#[to_keep]\n",
    "#all_leagues.to_csv(os.path.join(DATA_PATH,'all_leagues.csv'))\n",
    "all_leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>AC</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Malaga</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Coruna</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>Santander</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP1</td>\n",
       "      <td>09/09/00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>Espanol</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Annan Athletic</td>\n",
       "      <td>Kelty Hearts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Cowdenbeath</td>\n",
       "      <td>Albion Rvs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Forfar</td>\n",
       "      <td>Stenhousemuir</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Stirling</td>\n",
       "      <td>Edinburgh City</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>SC3</td>\n",
       "      <td>30/04/2022</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Stranraer</td>\n",
       "      <td>Elgin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157784 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Div        Date   Time        HomeTeam        AwayTeam  FTHG  FTAG FTR  \\\n",
       "0    SP1    09/09/00    NaN       Barcelona          Malaga   2.0   1.0   H   \n",
       "1    SP1    09/09/00    NaN       La Coruna      Ath Bilbao   2.0   0.0   H   \n",
       "2    SP1    09/09/00    NaN     Real Madrid        Valencia   2.0   1.0   H   \n",
       "3    SP1    09/09/00    NaN        Sociedad       Santander   2.0   2.0   D   \n",
       "4    SP1    09/09/00    NaN        Zaragoza         Espanol   1.0   2.0   A   \n",
       "..   ...         ...    ...             ...             ...   ...   ...  ..   \n",
       "175  SC3  30/04/2022  15:00  Annan Athletic    Kelty Hearts   1.0   2.0   A   \n",
       "176  SC3  30/04/2022  15:00     Cowdenbeath      Albion Rvs   0.0   1.0   A   \n",
       "177  SC3  30/04/2022  15:00          Forfar   Stenhousemuir   0.0   0.0   D   \n",
       "178  SC3  30/04/2022  15:00        Stirling  Edinburgh City   5.0   0.0   H   \n",
       "179  SC3  30/04/2022  15:00       Stranraer           Elgin   2.0   0.0   H   \n",
       "\n",
       "     HTHG  HTAG  ...   AC   HY   AY   HR   AR  B365H  B365D  B365A  B365>2.5  \\\n",
       "0     2.0   0.0  ...  NaN  NaN  NaN  NaN  NaN    NaN    NaN    NaN       NaN   \n",
       "1     0.0   0.0  ...  NaN  NaN  NaN  NaN  NaN    NaN    NaN    NaN       NaN   \n",
       "2     0.0   0.0  ...  NaN  NaN  NaN  NaN  NaN    NaN    NaN    NaN       NaN   \n",
       "3     0.0   0.0  ...  NaN  NaN  NaN  NaN  NaN    NaN    NaN    NaN       NaN   \n",
       "4     0.0   0.0  ...  NaN  NaN  NaN  NaN  NaN    NaN    NaN    NaN       NaN   \n",
       "..    ...   ...  ...  ...  ...  ...  ...  ...    ...    ...    ...       ...   \n",
       "175   1.0   2.0  ...  3.0  1.0  1.0  0.0  0.0    3.3   3.60   1.85      1.66   \n",
       "176   0.0   0.0  ...  3.0  3.0  1.0  0.0  0.0    NaN    NaN    NaN       NaN   \n",
       "177   0.0   0.0  ...  3.0  0.0  1.0  0.0  0.0    1.9   3.25   3.50      1.88   \n",
       "178   4.0   0.0  ...  2.0  0.0  1.0  0.0  0.0    2.6   3.10   2.70      2.15   \n",
       "179   0.0   0.0  ...  5.0  1.0  3.0  0.0  0.0    2.1   3.25   3.10      1.95   \n",
       "\n",
       "     B365<2.5  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "..        ...  \n",
       "175      2.15  \n",
       "176       NaN  \n",
       "177      1.98  \n",
       "178      1.66  \n",
       "179      1.90  \n",
       "\n",
       "[157784 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep = ['Div','Date','Time', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC','AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A', 'B365>2.5', 'B365<2.5']\n",
    "all_leagues = eu_leagues[to_keep]\n",
    "#all_leagues.to_csv(os.path.join(DATA_PATH,'all_leagues.csv'))\n",
    "all_leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WDDDEal5v4dD"
   },
   "outputs": [],
   "source": [
    "def get_matchweek(playing_stat, week_step):\n",
    "    \"\"\"\n",
    "    Adds matchweek feature to dataset\n",
    "    \"\"\"\n",
    "    j = 1\n",
    "    MatchWeek = []\n",
    "    for i in range(len(playing_stat)):\n",
    "        MatchWeek.append(j)\n",
    "        if ((i + 1)% week_step) == 0:\n",
    "            j += 1\n",
    "    playing_stat['MW'] = MatchWeek\n",
    "    return playing_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TXJ4N6zOv4dE"
   },
   "outputs": [],
   "source": [
    "from numpy.ma.core import diagonal\n",
    "\n",
    "def get_goals_scored(playing_stat):\n",
    "    # Get the number of matchweeks in the season\n",
    "    mw = max(playing_stat['MW'])\n",
    "    \n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
    "        teams[i] = []\n",
    "    \n",
    "    # build dict where value is a list of goals scored per match\n",
    "    for i in range(len(playing_stat)):\n",
    "        \n",
    "        HTGS = playing_stat.iloc[i]['FTHG']\n",
    "        ATGS = playing_stat.iloc[i]['FTAG']\n",
    "        teams[playing_stat.iloc[i].HomeTeam].append(HTGS)\n",
    "        teams[playing_stat.iloc[i].AwayTeam].append(ATGS)\n",
    "    \n",
    "\n",
    "    # -------To get the real matchweek\n",
    "    keys = list(teams.keys())\n",
    "    max_weeks = 0\n",
    "\n",
    "    for key in keys:\n",
    "      if max_weeks < len(teams[key]):\n",
    "        max_weeks = len(teams[key])\n",
    "    # real_mw = len(teams[keys[0]])\n",
    "    real_mw = max_weeks\n",
    "    # Create a dataframe for goals scored where rows are teams and cols are matchweek.\n",
    "    GoalsScored = pd.DataFrame(data=teams, index= [i for i in range(real_mw)]).T  # ------mv became real_mv which is the real number of matches a team played\n",
    "    GoalsScored[0] = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # Aggregate to get uptil that point\n",
    "    for i in range(2, real_mw):\n",
    "      GoalsScored[i] = GoalsScored[i] + GoalsScored[i-1]\n",
    "\n",
    "    return GoalsScored\n",
    "\n",
    "# Gets the goals conceded agg arranged by teams and matchweek\n",
    "def get_goals_conceded(playing_stat):\n",
    "    # Get the number of matchweeks in the season\n",
    "    mw = max(playing_stat['MW'])\n",
    "    \n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
    "        teams[i] = []\n",
    "    \n",
    "    # build dict where value is a list of goals conceded per match\n",
    "    for i in range(len(playing_stat)):\n",
    "        ATGC = playing_stat.iloc[i]['FTHG']\n",
    "        HTGC = playing_stat.iloc[i]['FTAG']\n",
    "        teams[playing_stat.iloc[i].HomeTeam].append(HTGC)\n",
    "        teams[playing_stat.iloc[i].AwayTeam].append(ATGC)\n",
    "    \n",
    "    # Create a dataframe for goals conceded where rows are teams and cols are matchweek.\n",
    "    # print(\"error to happen now:\", teams)\n",
    "    GoalsConceded = pd.DataFrame(data=teams).T  #, index = [i for i in range(mw)]).T\n",
    "    # print(\"error happened:\")\n",
    "    GoalsConceded[0] = 0\n",
    "\n",
    "    # -------To get the real matchweek\n",
    "    keys = list(teams.keys())\n",
    "    real_mw = len(teams[keys[0]])\n",
    "    # Aggregate to get uptil that point\n",
    "\n",
    "    for i in range(1, real_mw):\n",
    "        GoalsConceded[i] = GoalsConceded[i] + GoalsConceded[i-1]\n",
    "    return GoalsConceded\n",
    "\n",
    "def get_goal_stats(playing_stat, week_step):\n",
    "    GC = get_goals_conceded(playing_stat)\n",
    "    GS = get_goals_scored(playing_stat)\n",
    "   \n",
    "    j = 0\n",
    "    HTGS = []\n",
    "    ATGS = []\n",
    "    HTGC = []\n",
    "    ATGC = []\n",
    "    for i in range(len(playing_stat)):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        HTGS.append(GS.loc[ht][j])\n",
    "        ATGS.append(GS.loc[at][j])\n",
    "        HTGC.append(GC.loc[ht][j])\n",
    "        ATGC.append(GC.loc[at][j])\n",
    "        \n",
    "        \n",
    "        if ((i + 1)% week_step) == 0:\n",
    "            j += 1\n",
    "        \n",
    "    playing_stat['HTGS'] = HTGS\n",
    "    playing_stat['ATGS'] = ATGS\n",
    "    playing_stat['HTGC'] = HTGC\n",
    "    playing_stat['ATGC'] = ATGC\n",
    "    \n",
    "    return playing_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rjsC4h0pv4dF"
   },
   "outputs": [],
   "source": [
    "# Retrospective points\n",
    "def get_points(result):\n",
    "    if result == 'W':\n",
    "        return 3\n",
    "    elif result == 'D':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_cumulative_points(matchres, mw):\n",
    "    matchres_points = matchres.applymap(get_points)\n",
    "    for i in range(2, mw+1):\n",
    "        matchres_points[i] = matchres_points[i] + matchres_points[i-1]\n",
    "        \n",
    "    matchres_points.insert(column =0, loc = 0, value = [0*i for i in range(matchres.shape[0])]) \n",
    "    return matchres_points\n",
    "\n",
    "def get_match_result(playing_stat):\n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat.groupby('HomeTeam').mean().T.columns:\n",
    "        teams[i] = []\n",
    "\n",
    "    # build dict where value is list of match results\n",
    "    for i in range(len(playing_stat)):\n",
    "        if playing_stat.iloc[i].FTR == 'H':\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('W')\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('L')\n",
    "        elif playing_stat.iloc[i].FTR == 'A':\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('W')\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('L')\n",
    "        else:\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('D')\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('D')\n",
    "            \n",
    "\n",
    "    # To get the real matchweek\n",
    "    keys = list(teams.keys())\n",
    "    real_mw = len(teams[keys[0]])\n",
    "\n",
    "    return pd.DataFrame(data=teams, index = [i for i in range(1, real_mw+1)]).T\n",
    "\n",
    "def get_agg_points(playing_stat, week_step):\n",
    "    matchres = get_match_result(playing_stat)\n",
    "    cum_pts = get_cumulative_points(matchres, max(playing_stat['MW']))\n",
    "    HTP = []\n",
    "    ATP = []\n",
    "    j = 0\n",
    "    for i in range(len(playing_stat)):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        HTP.append(cum_pts.loc[ht][j])\n",
    "        ATP.append(cum_pts.loc[at][j])\n",
    "\n",
    "        if ((i + 1)% week_step) == 0:\n",
    "            j += 1\n",
    "            \n",
    "    playing_stat['HTP'] = HTP\n",
    "    playing_stat['ATP'] = ATP\n",
    "    return playing_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "23W0sxvfv4dG"
   },
   "outputs": [],
   "source": [
    "def get_form(playing_stat,num):\n",
    "    form = get_match_result(playing_stat)\n",
    "    form_final = form.copy()\n",
    "    for i in range(num, max(playing_stat['MW'])+1):\n",
    "        form_final[i] = ''\n",
    "        j = 0\n",
    "        while j < num:\n",
    "            form_final[i] += form[i-j]\n",
    "            j += 1\n",
    "    return form_final\n",
    "\n",
    "def add_form(playing_stat,num, week_step):\n",
    "    form = get_form(playing_stat,num)\n",
    "    h = ['M' for i in range(num * 10)]  # since form is not available for n MW (n*10)\n",
    "    a = ['M' for i in range(num * 10)]\n",
    "    \n",
    "    j = num\n",
    "    for i in range((num*10),playing_stat.shape[0]):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        \n",
    "        past = form.loc[ht][j]  # get past n results\n",
    "        h.append(past[num-1])   # 0 index is most recent\n",
    "        \n",
    "        past = form.loc[at][j]  # get past n results.\n",
    "        a.append(past[num-1])   # 0 index is most recent\n",
    "        \n",
    "        if ((i + 1)% week_step) == 0:\n",
    "            j = j + 1\n",
    "\n",
    "    playing_stat['HM' + str(num)] = h                 \n",
    "    playing_stat['AM' + str(num)] = a\n",
    "\n",
    "    \n",
    "    return playing_stat\n",
    "\n",
    "\n",
    "def add_form_df(playing_statistics, week_step):\n",
    "    playing_statistics = add_form(playing_statistics,1, week_step)\n",
    "    playing_statistics = add_form(playing_statistics,2, week_step)\n",
    "    playing_statistics = add_form(playing_statistics,3, week_step)\n",
    "    playing_statistics = add_form(playing_statistics,4, week_step)\n",
    "    playing_statistics = add_form(playing_statistics,5, week_step)\n",
    "    return playing_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXeu7yuRv4dH"
   },
   "source": [
    "The function below adds previous league position as a feature. If the team has been promoted we will use 18 as a default.\n",
    "\n",
    "To scrape this information from wikipedia uncomment the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H3f2oakgv4dJ"
   },
   "outputs": [],
   "source": [
    "# Gets the form points.\n",
    "def get_form_points(string):\n",
    "    total = 0\n",
    "    for letter in string:\n",
    "        total += get_points(letter)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JHf7NjthdYx",
    "outputId": "30cfce17-8a06-4798-e336-2181e03b88fe"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5252/3127651003.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mdf\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mget_matchweek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweek_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_goal_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweek_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_agg_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweek_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_form_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweek_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5252/1149533542.py\u001b[0m in \u001b[0;36mget_goal_stats\u001b[1;34m(playing_stat, week_step)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_goal_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaying_stat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweek_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mGC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_goals_conceded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaying_stat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_goals_scored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplaying_stat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5252/1149533542.py\u001b[0m in \u001b[0;36mget_goals_conceded\u001b[1;34m(playing_stat)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Create a dataframe for goals conceded where rows are teams and cols are matchweek.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# print(\"error to happen now:\", teams)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mGoalsConceded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mteams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[1;31m#, index = [i for i in range(mw)]).T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;31m# print(\"error happened:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mGoalsConceded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "datasets = None\n",
    "flag = 0\n",
    "\n",
    "for country in dict_countries:\n",
    "  league = dict_countries[country]\n",
    "  df = all_leagues[(all_leagues['Div'] == league)]\n",
    "  df.dropna(subset=['Date'], axis=0, how='all', inplace=True)\n",
    "  df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "  week_step = len(df['HomeTeam'].unique()) // 2\n",
    "\n",
    "  df  = get_matchweek(df, week_step)\n",
    "  df = get_goal_stats(df, week_step)\n",
    "  df = get_agg_points(df, week_step)\n",
    "  df = add_form_df(df, week_step)\n",
    "\n",
    "  df['HTFormPtsStr'] = df['HM1'] + df['HM2'] + df['HM3'] + df['HM4'] + df['HM5']\n",
    "  df['ATFormPtsStr'] = df['AM1'] + df['AM2'] + df['AM3'] + df['AM4'] +df['AM5']\n",
    "\n",
    "  df['HTFormPts'] = df['HTFormPtsStr'].apply(get_form_points)\n",
    "  df['ATFormPts'] = df['ATFormPtsStr'].apply(get_form_points)\n",
    "\n",
    "  # Get doal difference\n",
    "  df['HTGD'] = df['HTGS'] - df['HTGC']\n",
    "  df['ATGD'] = df['ATGS'] - df['ATGC']\n",
    "\n",
    "  # Diff in points\n",
    "  df['DiffPts'] = df['HTP'] - df['ATP']\n",
    "\n",
    "  # Difference in form points, last 5 games\n",
    "  df['DiffFormPts'] = df['HTFormPts'] - df['ATFormPts']\n",
    "\n",
    "  # Scale DiffPts , DiffFormPts, HTGD, ATGD by Matchweek.\n",
    "  cols = ['HTGD','ATGD','DiffPts','DiffFormPts','HTP','ATP']\n",
    "  df.MW = df.MW.astype(float)\n",
    "\n",
    "  for col in cols:\n",
    "      df[col] = df[col] /df.MW\n",
    "\n",
    "  if flag == 0:\n",
    "    datasets = df\n",
    "    flag = 1\n",
    "  else:\n",
    "    datasets = datasets.append(df)\n",
    "\n",
    "datasets = datasets.assign(gameId=lambda df: range(1, len(datasets) + 1)).sort_values('gameId')\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm1dt4Q3v4dK"
   },
   "source": [
    "# Create EMA dataset\n",
    "\n",
    "We will now create a dataset of exponential moving-averages(EMA). To do this we first need to split the data so that each team is on a seperate row, instead of a match per row. This will make it easier to get the moving average. We then reassemble the data back to a match per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "t1dbLYwVv4dL",
    "outputId": "8f55a108-818c-4c4f-c6be-9a3234c157d9"
   },
   "outputs": [],
   "source": [
    "def create_df(df):\n",
    "    \"\"\"\n",
    "    Function to convert date to datetime and sort by gameId\n",
    "    \"\"\"\n",
    "    df = (df\n",
    "         .assign(Date=lambda df: pd.to_datetime(df.Date))\n",
    "         .pipe(lambda df: df.dropna(thresh=len(df) - 2, axis=1))  # Drop cols with NAs\n",
    "         .dropna(axis=0)  # Drop rows with NAs\n",
    "         .rename(columns={'Unnamed: 0': 'gameId'})\n",
    "         .sort_values('gameId')\n",
    "         .reset_index(drop=True)\n",
    "         )\n",
    "    return df\n",
    "\n",
    "df = datasets.fillna(method=\"ffill\")\n",
    "df = create_df(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wwJ7MjLv4dK"
   },
   "outputs": [],
   "source": [
    "#df = df.drop(['FTHG', 'FTAG', 'HomeTeamLP', 'AwayTeamLP'], 1)\n",
    "#df = df.drop(['FTHG', 'FTAG'], 1)\n",
    "# Rearranging columns\n",
    "cols = ['Date', 'season', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTGS', 'ATGS', \n",
    "        'HTGC', 'ATGC', 'HTP', 'ATP', 'B365H', 'B365D', \n",
    "        'B365A', 'HM1', 'HM2', 'HM3', 'HM4', 'HM5', 'AM1', 'AM2', 'AM3', 'AM4', 'AM5', 'gameId']\n",
    "\n",
    "league_data = df[cols]\n",
    "league_data.to_csv('league_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "x7hIb4_Lv4dL",
    "outputId": "2deba366-8d8c-4263-b9b7-2bb684e54a7d"
   },
   "outputs": [],
   "source": [
    "def create_multiline_df_stats(old_stats_df):\n",
    "    # Create a list of columns we want and their mappings to more interpretable names\n",
    "    home_stats_cols = ['Date', 'season', 'HomeTeam', 'FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY',\n",
    "                       'HR', 'AR']\n",
    "    \n",
    "    away_stats_cols = ['Date', 'season', 'AwayTeam', 'FTAG', 'FTHG', 'HTAG', 'HTHG', 'AS', 'HS', 'AST', 'HST', 'AF', 'HF', 'AC', 'HC', 'AY', 'HY',\n",
    "                       'AR', 'HR']\n",
    "    \n",
    "    stats_cols_mapping = ['Date', 'season', 'Team', 'goalsFor', 'goalsAgainst', 'halfTimeGoalsFor', 'halfTimeGoalsAgainst', 'shotsFor',\n",
    "                          'shotsAgainst', 'shotsOnTargetFor', 'shotsOnTargetAgainst', 'freesFor', 'freesAgainst', \n",
    "                          'cornersFor', 'cornersAgainst', 'yellowsFor', 'yellowsAgainst', 'redsFor', 'redsAgainst']\n",
    "    \n",
    "    # Create a dictionary of the old column names to new column names\n",
    "    home_mapping = {old_col: new_col for old_col, new_col in zip(home_stats_cols, stats_cols_mapping)}\n",
    "    away_mapping = {old_col: new_col for old_col, new_col in zip(away_stats_cols, stats_cols_mapping)}\n",
    "    \n",
    "    # Put each team onto an individual row\n",
    "    multi_line_stats = (old_stats_df[['gameId'] + home_stats_cols] # Filter for only the home team columns\n",
    "                    .rename(columns=home_mapping) # Rename the columns\n",
    "                    .assign(homeGame=1) # Assign homeGame=1 so that we can use a general function later\n",
    "                    .append((old_stats_df[['gameId'] + away_stats_cols]) # Append the away team columns\n",
    "                            .rename(columns=away_mapping) # Rename the away team columns\n",
    "                            .assign(homeGame=0), sort=True)\n",
    "                    .sort_values(by='gameId') # Sort the values\n",
    "                    .reset_index(drop=True))\n",
    "    return multi_line_stats\n",
    "def create_stats_features_ema(stats, span):\n",
    "    # Create a restructured DataFrames so that we can calculate EMA\n",
    "    multi_line_stats = create_multiline_df_stats(stats)\n",
    "    \n",
    "    # Create a copy of the DataFrame\n",
    "    ema_features = multi_line_stats[['Date', 'season', 'gameId', 'Team', 'homeGame']].copy()\n",
    "    \n",
    "    # Get the columns that we want to create EMA for\n",
    "    feature_names = multi_line_stats.drop(columns=['Date', 'season', 'gameId', 'Team', 'homeGame']).columns\n",
    "    \n",
    "    # Loop over the features\n",
    "    for feature_name in feature_names:\n",
    "        feature_ema = (multi_line_stats.groupby('Team')[feature_name] # Calculate the EMA\n",
    "                                                  .transform(lambda row: row.ewm(span=span, min_periods=2)\n",
    "                                                             .mean()\n",
    "                                                             .shift(1))) # Shift the data down 1 so we don't leak data\n",
    "        ema_features[feature_name] = feature_ema # Add the new feature to the DataFrame\n",
    "    return ema_features\n",
    "\n",
    "# Add weighted average to each row with a span of 50.\n",
    "df = create_stats_features_ema(df, 50)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRGfTOf_v4dM"
   },
   "source": [
    "The span parameter controls the decay for EMA. I tried various settings and found 50 to be the most useful.\n",
    "\n",
    "Now that we have added the EMA stats we can restructure the dataset back to having a match on each row. We then save it as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "bCP1vMNgv4dM",
    "outputId": "f2b07b82-6ca0-4f30-b68f-05db07ef0a2f"
   },
   "outputs": [],
   "source": [
    "def restructure_stats_features(stats_features):\n",
    "    non_features = ['homeGame', 'Team', 'gameId']\n",
    "\n",
    "    stats_features_restructured = (stats_features.query('homeGame == 1')\n",
    "                                    .rename(columns={col: 'f_' + col + 'Home' for col in stats_features.columns if col not in non_features})\n",
    "                                    .rename(columns={'Team': 'HomeTeam'})\n",
    "                                    .pipe(pd.merge, (stats_features.query('homeGame == 0')\n",
    "                                                        .rename(columns={'Team': 'AwayTeam'})\n",
    "                                                        .rename(columns={col: 'f_' + col + 'Away' for col in stats_features.columns \n",
    "                                                                         if col not in non_features})), on=['gameId'])\n",
    "                                    .dropna())\n",
    "    return stats_features_restructured\n",
    "\n",
    "df = restructure_stats_features(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fl4lOoBev4dM",
    "outputId": "152ea441-7f7b-4187-efa4-21b2bae69722"
   },
   "outputs": [],
   "source": [
    "df.to_csv('EMA_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cto9Qu-Fv4dN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "\n",
    "from keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "tf.random.set_seed(42)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIXbYNP7v4dN"
   },
   "source": [
    "# Prepare the data\n",
    "\n",
    "We first need to load both our league-data and EMA data and combine these together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "4oL3tjAYv4dN",
    "outputId": "d8f8e9dd-c4e8-43e0-c2eb-6056d51607ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "league_data = pd.read_csv('league_data.csv')\n",
    "league_data.drop(['Unnamed: 0', 'Date',  \n",
    "                 'HTGS', 'ATGS', 'HTGC', 'ATGC', 'HM1', 'HM2', 'HM3', \n",
    "                 'HM4', 'HM5', 'AM1', 'AM2', 'AM3', 'AM4', 'AM5'], 1, inplace=True)\n",
    "league_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "tOHETrc2v4dN",
    "outputId": "18ef022f-c660-419a-efe0-203c30060075"
   },
   "outputs": [],
   "source": [
    "EMA_data = pd.read_csv('EMA_data.csv')\n",
    "EMA_data.drop(['Unnamed: 0', 'f_DateHome', 'f_seasonHome', \n",
    "               'homeGame_x', 'f_yellowsAgainstAway', 'f_yellowsForAway',\n",
    "               'f_yellowsAgainstHome', 'f_yellowsForHome', 'f_DateAway', 'f_seasonAway', \n",
    "              'homeGame_y'], 1, inplace=True)\n",
    "l = list(EMA_data['gameId'])\n",
    "league_data = league_data[league_data['gameId'].isin(l)]\n",
    "EMA_data = EMA_data.set_index('gameId')\n",
    "league_data = league_data.set_index('gameId')\n",
    "EMA_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "eu0V6_Bd-g_4",
    "outputId": "8c2aba4f-583b-49bb-8b72-5ec60339e5c9"
   },
   "outputs": [],
   "source": [
    "league_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "QueAfjSBv4dN",
    "outputId": "6b9f6b17-c344-449e-9225-e00c1ae50b7b"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([EMA_data, league_data], axis = 1).dropna(axis=0)\n",
    "df.to_csv('test.csv')\n",
    "league_data = league_data[league_data.columns.difference(['HomeTeam', 'AwayTeam', 'gameId'])]\n",
    "df = pd.concat([EMA_data, league_data], axis = 1).dropna(axis=0)\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1IHo24hpgtf"
   },
   "source": [
    "# Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6IWjdr3pTAn"
   },
   "outputs": [],
   "source": [
    "cols_drop = ['HomeTeam','AwayTeam', 'B365H', 'B365D', 'B365A', 'FTR', 'season', 'gameId' ]\n",
    "mean_data = {}\n",
    "for i, row in df.iterrows():\n",
    "  team_pair = \"{}_{}\".format(row['HomeTeam'],row['AwayTeam'])\n",
    "  row = row.drop(cols_drop)\n",
    "  if team_pair in mean_data.keys():\n",
    "    for key in row.keys():\n",
    "      mean_data[team_pair][key].append(row[key])\n",
    "  else:\n",
    "    mean_data[team_pair] = {}\n",
    "    for key in row.keys():\n",
    "      mean_data[team_pair][key]=[row[key]]\n",
    "\n",
    "for team_pair in mean_data.keys():\n",
    "  for feature in mean_data[team_pair].keys():\n",
    "    mean_data[team_pair][feature] = sum(mean_data[team_pair][feature])/len(mean_data[team_pair][feature])\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "  team_pair = \"{}_{}\".format(row['HomeTeam'],row['AwayTeam'])\n",
    "  row = row.drop(cols_drop)\n",
    "  for key in row.keys():\n",
    "    df[key].iloc[i] = mean_data[team_pair][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "HQNccL2OL1PA",
    "outputId": "d98ac246-ea4a-4d13-e825-09270286285f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LD-m37lwbpR"
   },
   "source": [
    "# One hot encoding the team data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7K0C6-3wbBg"
   },
   "outputs": [],
   "source": [
    "def encode_and_bind(df, feature_to_encode):\n",
    "    dummies = pd.get_dummies(df[feature_to_encode], dtype=bool)\n",
    "    df = df.drop(columns = feature_to_encode, axis=1)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    return (df)\n",
    "df = encode_and_bind(df, ['HomeTeam', 'AwayTeam'])\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxgPJ3MXv4dO"
   },
   "source": [
    "# Cleaning and splitting the data\n",
    "\n",
    "Because the machine -learning model only takes numeric input we will change our labels from strings to integers and use categorical cross-entropy as our loss function. We will also scale our data using sklearn StandardScaler.\n",
    "\n",
    "First we will seperate the labels from the rest of our data and split into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hrdPO-lv4dO",
    "outputId": "c1788327-4492-4e0e-85a6-bd3752644e4d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#training_data = df.loc[df['season'] != 1920].reset_index(drop=True)\n",
    "#testing_data = df.loc[df['season'] == 708].reset_index(drop=True)\n",
    "\n",
    "training_data, testing_data = train_test_split(df, test_size=0.20, stratify=df['FTR'],random_state=42)\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "testing_data = testing_data.reset_index(drop=True)\n",
    "\n",
    "X_train = training_data.drop([ 'FTR', 'season', 'gameId' ], 1)\n",
    "Y_train = training_data['FTR']\n",
    "\n",
    "X_test = testing_data.drop(['FTR', 'season', 'gameId' ], 1)\n",
    "Y_test = testing_data['FTR']\n",
    "all_cols = X_train.columns \n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vkbmu8Pv4dP"
   },
   "outputs": [],
   "source": [
    "def transform_results(results):\n",
    "    transformed = []\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == 'H':\n",
    "            transformed.append(0)\n",
    "        elif results[i] == 'A':\n",
    "            transformed.append(2)\n",
    "        else:\n",
    "            transformed.append(1)\n",
    "    return np.array(transformed)\n",
    "            \n",
    "Y_train = transform_results(Y_train)\n",
    "Y_test = transform_results(Y_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo5g7ioqv4dP",
    "outputId": "2b04fb9b-86b8-4cf6-8ee7-1e0a5f6f20ab"
   },
   "outputs": [],
   "source": [
    "print('Number of matches in training data:', X_train.shape[0])\n",
    "print('Number of matches in test data:', X_test.shape[0])\n",
    "print('Number of features:', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgXha9Xuv4dP"
   },
   "source": [
    "# Build the model\n",
    "\n",
    "Now we have cleaned the data we can now create our model and train it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_TCY6Oyv4dP",
    "outputId": "4aa38e3f-812b-4f1c-e7c3-a5c887cb9eca"
   },
   "outputs": [],
   "source": [
    "# input dimension is number of features\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "activation_func = 'relu'\n",
    "kernel_init = 'glorot_normal'\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Dense(48, input_shape=(input_dim,), activation=activation_func),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation=activation_func),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation=activation_func),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "opt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "es = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "              # callbacks=[es], epochs=500, verbose=0)\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "              callbacks=[], epochs=500, verbose=0) # gets (75% - 88%) acc for the validation set\n",
    "train_loss, train_acc = model.evaluate(X_train, Y_train)\n",
    "val_loss, val_acc = model.evaluate(X_test, Y_test)\n",
    "print('Training loss:', train_loss)\n",
    "print('Training accuracy:', train_acc)\n",
    "print('Validation loss:', val_loss)\n",
    "print('Validation accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vwHnGnMv4dQ"
   },
   "source": [
    "We are getting around 65% on training and 62% on validation. This is good as is well above the bookies accuracy. Once we are happy with how the model is performing we can check the accuracy on the test set. \n",
    "\n",
    "First let's get a more detailed breakdown of the model's accuracy by using classification report. This will show how we perform for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDxuXfq8v4dQ",
    "outputId": "224b09af-51f1-4943-8a5d-461c7b1ddc15"
   },
   "outputs": [],
   "source": [
    "labels = ['Home', 'Draw', 'Away']\n",
    "y_preds = model.predict(X_test)\n",
    "y_pred_argmax = [np.argmax(i) for i in y_preds]\n",
    "print(classification_report(Y_test, y_pred_argmax, target_names=labels))\n",
    "print(confusion_matrix(Y_test, y_pred_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFiaoMb4v4dR"
   },
   "outputs": [],
   "source": [
    "# Saving best model\n",
    "model.save('25Nov19.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcI1xi69v4dR"
   },
   "source": [
    "# Check test accuracy\n",
    "\n",
    "Once we have our model performing well we will use our 'holdout' test-set, season 19/20 so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgAdohwtv4dR",
    "outputId": "f4d2883a-380c-42d0-ef34-97503e4d01f7"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bl4iQetv4dR",
    "outputId": "e2923f58-6063-4921-99fc-56b054b686b1"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "y_pred_argmax = [np.argmax(i) for i in y_preds]\n",
    "print(classification_report(Y_test, y_pred_argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTm0ydhPv4dR"
   },
   "source": [
    "# Create a betting strategy\n",
    "\n",
    "Now that we have an accurate model let's see if we can make it as profitable as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl29anvYv4dR"
   },
   "source": [
    "Our confusion matrix looks good. I mainly wanted to check the performance for draws as these are difficult to predict, the results are ok.\n",
    "\n",
    "We will now use the for-loop below to see how much we would have won had we bet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "BEgPumeMv4dS",
    "outputId": "0e3b9cfe-b28c-4a37-991b-c36c69040f50"
   },
   "outputs": [],
   "source": [
    "def get_team_names(row):\n",
    "  ht = \"\"\n",
    "  at = \"\"\n",
    "  for key in row.keys():\n",
    "    if key.startswith(\"HomeTeam\") and row[key].item() == True:\n",
    "      ht = key.split(\"_\")[1]\n",
    "    if key.startswith(\"AwayTeam\") and row[key].item() == True:\n",
    "      at = key.split(\"_\")[1]\n",
    "  return ht, at\n",
    "\n",
    "def get_preds(pred):\n",
    "  if pred == 0:\n",
    "    return 'H'\n",
    "  elif pred == 1:\n",
    "    return 'D'\n",
    "  return 'A'\n",
    "  \n",
    "funds = 100\n",
    "wager = 10\n",
    "favourites = 0\n",
    "no_bets = 0\n",
    "min_diff = 0.03\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "pred_dict = {\n",
    "    \"HomeTeam\":[],\n",
    "    \"AwayTeam\":[],\n",
    "    \"prediction\":[],\n",
    "    \"actual\":[],\n",
    "    \"favourite\":[],\n",
    "    \"proba_H_(%)\":[],\n",
    "    \"proba_D_(%)\":[],\n",
    "    \"proba_A_(%)\":[],\n",
    "    \"B365H\":[],\n",
    "    \"B365A\":[],\n",
    "    \"B365D\":[],\n",
    "    \"funds\": [],\n",
    "}\n",
    "\n",
    "\n",
    "  \n",
    "for i in range(len(X_test)):\n",
    "    prediction = np.argmax(y_preds[i])\n",
    "    # print('\\nPrediction', prediction)\n",
    "    # print('Actual', Y_test[i])\n",
    "    # print('Favourite', np.argmin([testing_data['B365H'][i], testing_data['B365D'][i], \n",
    "    #                               testing_data['B365A'][i]]))\n",
    "    # print('Prediction proba', y_preds[i])\n",
    "    # print('Home, Draw and Away odds', testing_data['B365H'][i],       \n",
    "    #       testing_data['B365D'][i], testing_data['B365A'][i])\n",
    "    pred_dict[\"prediction\"].append(get_preds(prediction))\n",
    "    pred_dict[\"actual\"].append(get_preds(Y_test[i]))\n",
    "    pred_dict[\"favourite\"].append(get_preds(np.argmin([testing_data['B365H'][i], testing_data['B365D'][i], \n",
    "                                  testing_data['B365A'][i]])))\n",
    "    pred_dict[\"proba_H_(%)\"].append(y_preds[i][0] * 100)\n",
    "    pred_dict[\"proba_D_(%)\"].append(y_preds[i][1] * 100)\n",
    "    pred_dict[\"proba_A_(%)\"].append(y_preds[i][2] * 100)\n",
    "\n",
    "    pred_dict[\"B365H\"].append(testing_data['B365H'][i])\n",
    "    pred_dict[\"B365A\"].append(testing_data['B365A'][i])\n",
    "    pred_dict[\"B365D\"].append(testing_data['B365D'][i])\n",
    "    teams = get_team_names(testing_data.iloc[[i]])\n",
    "    pred_dict['HomeTeam'].append(teams[0])\n",
    "    pred_dict['AwayTeam'].append(teams[1])\n",
    "\n",
    "    if prediction == 0:\n",
    "        odds_diff = y_preds[i][prediction] - (1/testing_data['B365H'][i])\n",
    "        if odds_diff > min_diff:\n",
    "            if prediction == np.argmin([testing_data['B365H'][i], testing_data['B365D'][i], \n",
    "                                  testing_data['B365A'][i]]):\n",
    "                favourites +=1\n",
    "                \n",
    "            if  prediction == Y_test[i]:\n",
    "                funds += (wager * testing_data['B365H'][i]) - wager\n",
    "            else:\n",
    "                funds -= wager\n",
    "        else:\n",
    "            no_bets +=1\n",
    "            \n",
    "    elif prediction == 1:\n",
    "        odds_diff = y_preds[i][prediction] - (1/testing_data['B365D'][i])\n",
    "        if odds_diff > min_diff:\n",
    "            if prediction == np.argmin([testing_data['B365H'][i], testing_data['B365D'][i], \n",
    "                                  testing_data['B365A'][i]]):\n",
    "                favourites +=1\n",
    "            if  prediction == Y_test[i]:\n",
    "                funds +=( wager * testing_data['B365D'][i]) - wager\n",
    "            else:\n",
    "                funds -= wager\n",
    "        else:\n",
    "            no_bets +=1\n",
    "    else:\n",
    "        odds_diff = y_preds[i][prediction] - (1/testing_data['B365A'][i])\n",
    "        if odds_diff >  min_diff:\n",
    "            if prediction == np.argmin([testing_data['B365H'][i], testing_data['B365D'][i], \n",
    "                                  testing_data['B365A'][i]]):\n",
    "                favourites +=1\n",
    "            if  prediction == Y_test[i]:\n",
    "                funds += (wager * testing_data['B365A'][i]) - wager\n",
    "            else:\n",
    "                funds -= wager\n",
    "        else:\n",
    "            no_bets +=1\n",
    "   \n",
    "    #print('Funds', funds)\n",
    "    pred_dict[\"funds\"].append(funds)\n",
    "\n",
    "pred_df = pd.DataFrame(pred_dict)\n",
    "print(f'Betted on favourite {favourites} times out of {len(X_test)} matches.')\n",
    "print(f'No bet placed {no_bets} times')\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbCK_Sb5v4dS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#from scrapers import *\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOqc2qIvv4dS"
   },
   "source": [
    "# Predict upcoming games\n",
    "\n",
    "To predict upcoming games we will need to:\n",
    "1. Scrape upcoming fixtures with odds\n",
    "2. Concatentate these onto avg. results so far for the previous seson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5M6-fSvEOMu"
   },
   "outputs": [],
   "source": [
    "# league='F1'\n",
    "league = \"SP2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "xjWqn6v2v4dS",
    "outputId": "fbe8c666-167e-435c-d0dd-68cb82fb93b9"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    upcoming_data = pd.concat([pd.read_csv('https://www.football-data.co.uk/fixtures.csv')])\n",
    "except:\n",
    "    upcoming_data = pd.concat([pd.read_csv('https://www.football-data.co.uk/fixtures.csv', encoding=\"unicode_escape\")])\n",
    "    upcoming_data.Date = pd.to_datetime(upcoming_data.Date)\n",
    "fixtures = upcoming_data\n",
    "fixtures = upcoming_data[upcoming_data['Date'] != ''] #league variable \n",
    "#fixtures.dropna(axis=1, inplace=True)\n",
    "fixtures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4ISEndblv4dT",
    "outputId": "1e94edc8-a720-4780-85bd-a4cfce6ef127"
   },
   "outputs": [],
   "source": [
    "fixtures.drop(fixtures.columns.difference(['HomeTeam', 'AwayTeam', 'B365H', 'B365A', 'B365D']), axis=1, inplace=True)\n",
    "fixtures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2zWrIQVpHor"
   },
   "source": [
    "# Adding previous stats to upcoming_data\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfK8cw_HpHDB",
    "outputId": "2a378195-e67b-428f-97cb-89d60ce5cad2"
   },
   "outputs": [],
   "source": [
    "for i, row in fixtures.iterrows():\n",
    "  team_pair = \"{}_{}\".format(row['HomeTeam'], row['AwayTeam'])\n",
    "  if team_pair in mean_data.keys():\n",
    "    data = mean_data[team_pair]\n",
    "    for key in data.keys():\n",
    "      fixtures.loc[df.index[i], key] = mean_data[team_pair][key]\n",
    "  else:\n",
    "    print(\"dropping {} - {} team pair. Since previous data not available\".format(row['HomeTeam'], row['AwayTeam']))\n",
    "    fixtures.drop(index=i, axis=0, inplace=True)\n",
    "fixtures.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPHYtnEGuOur"
   },
   "source": [
    "# One hot encoding upcoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "zEXkn2K0uLsk",
    "outputId": "db69cc32-270a-496b-81e5-9775c5b040b8"
   },
   "outputs": [],
   "source": [
    "fixtures = encode_and_bind(fixtures, ['HomeTeam', 'AwayTeam'])\n",
    "fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsITCsLc5wDx"
   },
   "source": [
    "# Filling missing team inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hB8vU4NxzwTa",
    "outputId": "c06df263-4f43-453d-cc79-31f32bb59b33"
   },
   "outputs": [],
   "source": [
    "for i in all_cols:\n",
    "  if i not in fixtures.columns:\n",
    "    fixtures[i] = False\n",
    "fixtures.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmA2bbIrxsWY"
   },
   "source": [
    "# Predicting Upcoming (run until here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvb8Qn6Exwxt"
   },
   "outputs": [],
   "source": [
    "X_test = fixtures.to_numpy()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "rut0EtiwGXEk",
    "outputId": "e9414414-9d67-41f0-ebca-bea489a84ed3"
   },
   "outputs": [],
   "source": [
    "def get_team_names(row):\n",
    "  ht = \"\"\n",
    "  at = \"\"\n",
    "  for key in row.keys():\n",
    "    if key.startswith(\"HomeTeam\") and row[key].item() == True:\n",
    "      ht = key.split(\"_\")[1]\n",
    "    if key.startswith(\"AwayTeam\") and row[key].item() == True:\n",
    "      at = key.split(\"_\")[1]\n",
    "  return ht, at\n",
    "\n",
    "def get_preds(pred):\n",
    "  if pred == 0:\n",
    "    return 'H'\n",
    "  elif pred == 1:\n",
    "    return 'D'\n",
    "  return 'A'\n",
    "\n",
    "testing_data = fixtures\n",
    "pred_dict = {\n",
    "    \"HomeTeam\":[],\n",
    "    \"AwayTeam\":[],\n",
    "    \"prediction\":[],\n",
    "    \"proba_H_(%)\":[],\n",
    "    \"proba_D_(%)\":[],\n",
    "    \"proba_A_(%)\":[],\n",
    "    \"B365H\":[],\n",
    "    \"B365A\":[],\n",
    "    \"B365D\":[],\n",
    "}\n",
    "\n",
    "\n",
    "  \n",
    "for i in range(len(X_test)):\n",
    "    prediction = np.argmax(y_preds[i])\n",
    "    pred_dict[\"prediction\"].append(get_preds(prediction))\n",
    "    pred_dict[\"proba_H_(%)\"].append(y_preds[i][0] * 100)\n",
    "    pred_dict[\"proba_D_(%)\"].append(y_preds[i][1] * 100)\n",
    "    pred_dict[\"proba_A_(%)\"].append(y_preds[i][2] * 100)\n",
    "    pred_dict[\"B365H\"].append(testing_data['B365H'].iloc[i])\n",
    "    pred_dict[\"B365A\"].append(testing_data['B365A'].iloc[i])\n",
    "    pred_dict[\"B365D\"].append(testing_data['B365D'].iloc[i])\n",
    "    teams = get_team_names(testing_data.iloc[[i]])\n",
    "    pred_dict['HomeTeam'].append(teams[0])\n",
    "    pred_dict['AwayTeam'].append(teams[1])\n",
    "    \n",
    "pred_df = pd.DataFrame(pred_dict)\n",
    "pred_df # for leagues concatenate"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Good accuracy of new_last_one",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
